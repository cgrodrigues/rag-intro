{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def parse_experiments():\n",
    "    \"\"\" Get a list of secret experiment from ColdF  \"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/cgrodrigues/rag-intro/main/coldf_secret_experiments.txt\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        text = response.text\n",
    "\n",
    "        # Split the text using the experiment identifier as a delimiter\n",
    "        experiments = text.split('[Experiment')\n",
    "        \n",
    "        # Remove empty strings and reformat each experiment\n",
    "        experiments = ['[Experiment' + exp.strip() for exp in experiments if exp.strip()]\n",
    "        \n",
    "        return experiments\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch the file: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import numpy as np\n",
    "import chromadb\n",
    "\n",
    "\n",
    "def get_context_encoder_tokenizer():\n",
    "    \"\"\" Load the DPR context encoder and tokenizer. \"\"\"\n",
    "    context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "    context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "    return context_encoder, context_tokenizer\n",
    "\n",
    "def init_chroma_db(store_name:str=\"documents\"):\n",
    "    \"\"\" Initialize ChromaDB client. \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./cromadb\")\n",
    "    vector_store = chroma_client.get_or_create_collection(store_name)\n",
    "    return chroma_client, vector_store\n",
    "\n",
    "def chunk_embed_text(text, chunk_size, overlap_size, context_encoder, context_tokenizer):\n",
    "    \"\"\"Chunk the text into overlapping segments and generate embeddings for the text using a transformer model..\"\"\"\n",
    "\n",
    "    chunks = []\n",
    "    embeddings = []\n",
    "    ids = []\n",
    "    ct = 0\n",
    "    for chunk in text:\n",
    "        chunks.append(chunk)\n",
    "        inputs = context_tokenizer(chunk, return_tensors='pt')\n",
    "        embedding = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "        print(chunk, embedding, ct)\n",
    "        \n",
    "        ids.append(f\"id_{str(ct)}\")\n",
    "        ct += 1\n",
    "\n",
    "\n",
    "    # chunks = []\n",
    "    # embeddings = []\n",
    "    # ids = []\n",
    "    # start = 0\n",
    "    # ct = 0\n",
    "    # while start < len(text):\n",
    "    #     end = start + chunk_size\n",
    "    #     chunk = text[start:end]\n",
    "    #     chunks.append(chunk)\n",
    "    #     start += chunk_size - overlap_size\n",
    "\n",
    "    #     inputs = context_tokenizer(chunk, return_tensors='pt')\n",
    "    #     embedding = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "    #     embeddings.append(embedding)\n",
    "\n",
    "    #     print(chunk, embedding, ct)\n",
    "        \n",
    "    #     ids.append(f\"id_{str(ct)}\")\n",
    "    #     ct += 1\n",
    "\n",
    "    # print(f\"------------====>{embeddings}\")\n",
    "    return chunks, embeddings, ids\n",
    "\n",
    "\n",
    "def preprocess_text_to_chroma(text, vector_store, chunk_size, overlap_size, context_encoder, context_tokenizer): \n",
    "    \"\"\"Process text and store chunks in ChromaDB.\"\"\"\n",
    "    \n",
    "    chunks, embeddings, ids = chunk_embed_text(text, \n",
    "                                               chunk_size, \n",
    "                                               overlap_size, \n",
    "                                               context_encoder=context_encoder, \n",
    "                                               context_tokenizer=context_tokenizer)\n",
    "    vector_store.add(documents=chunks, embeddings=embeddings, ids=ids)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "chunk_size = 500  # Define your chunk size, each experiment has more or less \n",
    "overlap_size = 50  # Define your overlap size\n",
    "\n",
    "# Example text corpus\n",
    "text = parse_experiments()\n",
    "\n",
    "context_encoder, context_tokenizer = get_context_encoder_tokenizer()\n",
    "chroma_client, vector_store = init_chroma_db(\"documents\")\n",
    "preprocess_text_to_chroma(text, \n",
    "                          vector_store, \n",
    "                          chunk_size, \n",
    "                          overlap_size, \n",
    "                          context_tokenizer=context_tokenizer, \n",
    "                          context_encoder=context_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id_0\n",
      "Add of existing embedding ID: id_1\n",
      "Add of existing embedding ID: id_2\n",
      "Add of existing embedding ID: id_3\n",
      "Add of existing embedding ID: id_4\n",
      "Add of existing embedding ID: id_5\n",
      "Add of existing embedding ID: id_6\n",
      "Add of existing embedding ID: id_7\n",
      "Add of existing embedding ID: id_8\n",
      "Add of existing embedding ID: id_9\n",
      "Add of existing embedding ID: id_10\n",
      "Add of existing embedding ID: id_11\n",
      "Add of existing embedding ID: id_12\n",
      "Add of existing embedding ID: id_13\n",
      "Add of existing embedding ID: id_14\n",
      "Add of existing embedding ID: id_15\n",
      "Add of existing embedding ID: id_16\n",
      "Add of existing embedding ID: id_17\n",
      "Add of existing embedding ID: id_18\n",
      "Add of existing embedding ID: id_19\n",
      "Insert of existing embedding ID: id_0\n",
      "Insert of existing embedding ID: id_1\n",
      "Insert of existing embedding ID: id_2\n",
      "Insert of existing embedding ID: id_3\n",
      "Insert of existing embedding ID: id_4\n",
      "Insert of existing embedding ID: id_5\n",
      "Insert of existing embedding ID: id_6\n",
      "Insert of existing embedding ID: id_7\n",
      "Insert of existing embedding ID: id_8\n",
      "Insert of existing embedding ID: id_9\n",
      "Insert of existing embedding ID: id_10\n",
      "Insert of existing embedding ID: id_11\n",
      "Insert of existing embedding ID: id_12\n",
      "Insert of existing embedding ID: id_13\n",
      "Insert of existing embedding ID: id_14\n",
      "Insert of existing embedding ID: id_15\n",
      "Insert of existing embedding ID: id_16\n",
      "Insert of existing embedding ID: id_17\n",
      "Insert of existing embedding ID: id_18\n",
      "Insert of existing embedding ID: id_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['id_0', 'id_8', 'id_3', 'id_16', 'id_19', 'id_18', 'id_10', 'id_5', 'id_11', 'id_15']], 'distances': [[0.8525894004258584, 0.9353905196358957, 0.9482485195863827, 0.9590379392588978, 0.9841376880261145, 1.0198892389075616, 1.0525335040210608, 1.0530792117099146, 1.054134360354219, 1.0597632357084095]], 'metadatas': [[None, None, None, None, None, None, None, None, None, None]], 'embeddings': None, 'documents': [['[Experiment1]\\n[May 23, 2024]\\nThe first experiment focused on using palladium electrodes submerged in heavy water (deuterium oxide, D2O). Dr. Emily Jensen, Senior Physicist, led this trial. The procedure involved electrolysis at a constant current of 50 mA, aiming to induce cold fusion within the palladium lattice. Throughout the 12-hour process, temperatures were carefully monitored, maintaining a steady 25°C. Voltage readings were recorded every hour to observe any anomalies indicating fusion events. The experiment yielded promising preliminary results with minor heat generation detected, suggesting potential excess energy beyond chemical reactions.\\nTo ensure accuracy, additional measurements included the analysis of gas output. Both hydrogen and deuterium gas levels were monitored using a gas chromatograph, which revealed an increase in deuterium gas concentration over time. This increase suggested that deuterium nuclei might be fusing within the palladium lattice. Further isotopic analysis using mass spectrometry confirmed the presence of helium-4, a potential byproduct of fusion, indicating that cold fusion might indeed be occurring.', '[Experiment9]\\n[May 31, 2024]\\nDr. Anya Singh, Research Fellow, explored the use of a magnetic field in conjunction with palladium electrodes. The heavy water electrolyte contained a small percentage of lithium chloride. Electrolysis was performed at 85 mA, with temperatures controlled between 30°C and 35°C. Voltage and temperature readings were taken every 10 minutes. The introduction of a magnetic field significantly increased heat output, with energy surpassing input by 22% after 7 hours. This indicated that magnetic fields might enhance the cold fusion reaction.\\nFurther investigations included monitoring the magnetic field strength and its effect on deuterium absorption. The data suggested that the magnetic field facilitated better alignment of deuterium nuclei, enhancing fusion probabilities. Neutron and gamma radiation monitoring showed increased emissions consistent with enhanced fusion activity. The electrolyte analysis post-experiment revealed increased helium-4 and tritium content, further supporting the role of the magnetic field in enhancing cold fusion.', '[Experiment4]\\n[May 26, 2024]\\nDr. Michael Huang, Research Assistant, conducted an experiment using a combination of palladium and platinum electrodes. The heavy water electrolyte contained a small percentage of potassium carbonate to stabilize the reaction. Electrolysis was performed at 80 mA, with temperatures controlled between 28°C and 32°C. Measurements of voltage, current, and temperature were taken every 10 minutes. This experiment showed significant heat generation after 8 hours, with energy output exceeding input by 15%. The combination of materials proved to be effective in enhancing the cold fusion reaction.\\nFurther analysis included monitoring gamma radiation emissions using a scintillation counter. The data revealed low levels of gamma radiation, which could be indicative of nuclear reactions occurring within the electrolytic cell. Additionally, the electrolyte solution was analyzed for transmutation products, with trace amounts of tritium and helium-3 detected, suggesting that both fusion and secondary nuclear reactions might be taking place. The palladium-platinum combination demonstrated a unique synergy, potentially opening new avenues for optimizing cold fusion systems.', '[Experiment17]\\n[June 8, 4]\\nDr. Olivia Rodriguez, Research Fellow, conducted an experiment using palladium electrodes and a magnetic field in heavy water. The electrolyte contained a small percentage of lithium carbonate. Electrolysis was performed at 90 mA, with temperatures controlled between 31°C and 36°C. Voltage and temperature readings were taken every 10 minutes. The experiment yielded significant heat generation, with energy output surpassing input by 23% after 7 hours. The combination of materials, magnetic field, and electrolyte composition proved effective in enhancing cold fusion reactions.\\nDetailed investigations included monitoring the magnetic field strength and its effect on deuterium absorption. The data suggested that the magnetic field facilitated better alignment of deuterium nuclei, enhancing fusion probabilities. Neutron and gamma radiation monitoring showed increased emissions consistent with enhanced fusion activity. The electrolyte analysis post-experiment revealed increased helium-4 and tritium content, further supporting the role of the magnetic field in enhancing cold fusion.', \"[Experiment20]\\n[June 11, 2024]\\nDr. Hiroshi Tanaka, Chief Scientist, conducted an experiment using a combination of palladium and silver electrodes. Heavy water with a lithium chloride additive served as the electrolyte. Electrolysis was performed at 100 mA, with temperatures maintained at 30°C. Voltage and temperature readings were taken every 10 minutes. The experiment showed significant heat generation, with energy output surpassing input by 25% after 8 hours. The combination of palladium and silver, along with the lithium chloride electrolyte, proved to be highly effective in enhancing cold fusion reactions.\\nAdditional investigations included monitoring the electrodes' structural integrity using SEM and XRD. The analysis revealed substantial deuterium absorption and lattice changes within the palladium-silver electrodes. Isotopic analysis of the electrolyte showed increased helium-4 and tritium content, supporting the occurrence of fusion reactions. Neutron and gamma radiation monitoring confirmed increased emissions, consistent with nuclear activity. The palladium-silver combination demonstrated a unique synergy, enhancing the cold fusion process significantly.\", '[Experiment19]\\n[June 10, 2024]\\nDr. Natasha Ivanov, Junior Researcher, explored the use of a hybrid electrolyte containing heavy water and a small concentration of potassium hydroxide. Palladium electrodes were again employed, with the electrolysis current set at 95 mA. The temperature was maintained at 32°C, with readings taken every 10 minutes. Over 10 hours, there was a steady increase in heat production, reaching an energy output surpassing input by 20%. The potassium hydroxide appeared to facilitate better deuterium absorption, enhancing the cold fusion process.\\nNeutron detection and gamma radiation monitoring were employed to further understand the reaction dynamics. The neutron counts were significantly higher than the baseline, indicating increased fusion activity. Additionally, gamma radiation levels were monitored and found to be consistent with the fusion events. The electrolyte solution was analyzed post-experiment, revealing increased helium-4 content, further supporting the occurrence of fusion reactions. The palladium electrodes exhibited significant deuterium uptake, confirmed by post-experiment isotopic analysis.', \"[Experiment11]\\n[June 2, 2024]\\nDr. Maria Lopez, Junior Researcher, conducted an experiment using a combination of palladium and gold electrodes. Heavy water with a potassium carbonate additive served as the electrolyte. Electrolysis was performed at 95 mA, with temperatures maintained at 32°C. Voltage and temperature readings were taken every 10 minutes. The experiment showed a significant increase in heat output, with energy exceeding input by 19% after 8 hours. The combination of palladium and gold proved to be effective in enhancing cold fusion reactions.\\nAdditional tests included monitoring the electrodes' structural integrity using SEM and XRD. The analysis revealed significant deuterium absorption and lattice changes within the palladium-gold electrodes. Isotopic analysis of the electrolyte showed increased helium-4 and tritium content, supporting the occurrence of fusion reactions. Neutron and gamma radiation monitoring confirmed increased emissions, consistent with nuclear activity. The palladium-gold combination demonstrated a unique synergy, enhancing the cold fusion process.\", '[Experiment6]\\n[May 28, 2024]\\nIn this experiment, Dr. Ahmed Rashid, Lead Engineer, used a hybrid electrolyte containing heavy water and a small concentration of sodium hydroxide. Palladium electrodes were again employed, with the electrolysis current set at 90 mA. The temperature was maintained at 33°C, with readings taken every 10 minutes. Over 10 hours, there was a steady increase in heat production, reaching an energy output surpassing input by 20%. The sodium hydroxide appeared to facilitate better deuterium absorption, enhancing the cold fusion process.\\nNeutron detection and gamma radiation monitoring were employed to further understand the reaction dynamics. The neutron counts were significantly higher than the baseline, indicating increased fusion activity. Additionally, gamma radiation levels were monitored and found to be consistent with the fusion events. The electrolyte solution was analyzed post-experiment, revealing increased helium-4 content, further supporting the occurrence of fusion reactions. The palladium electrodes exhibited significant deuterium uptake, confirmed by post-experiment isotopic analysis.', '[Experiment12]\\n[June 3, 2024]\\nDr. Benjamin Park, Research Assistant, explored the use of high-pressure conditions with palladium electrodes in heavy water. Electrolysis was performed at 75 mA, with the pressure increased to 3 atmospheres. Temperatures were maintained at 28°C, with readings taken every 15 minutes. The experiment yielded a noticeable increase in heat output, with energy surpassing input by 21% after 6 hours. The high-pressure conditions appeared to enhance deuterium absorption, improving the cold fusion reaction.\\nFurther analysis included monitoring the gas output under high pressure, revealing increased deuterium and helium-4 levels. Neutron and gamma radiation emissions were also monitored, showing significant increases consistent with enhanced fusion activity. Post-experiment analysis of the palladium electrodes using XRD and SEM revealed substantial lattice deformations, indicative of high deuterium loading and fusion activity. The high-pressure conditions proved to be a crucial factor in optimizing cold fusion reactions.', '[Experiment16]\\n[June 7, 2024]\\nDr. David Morgan, Senior Chemist, tested the effects of varying pressure conditions using palladium electrodes in heavy water. Electrolysis was performed at 70 mA, with the pressure gradually increased to 4 atmospheres. Temperatures were maintained at 30°C, with readings taken every 15 minutes. The experiment showed a noticeable increase in heat output, with energy surpassing input by 22% after 6 hours. The high-pressure conditions appeared to enhance deuterium absorption, improving the cold fusion reaction.\\nFurther analysis included monitoring the gas output under high pressure, revealing increased deuterium and helium-4 levels. Neutron and gamma radiation emissions were also monitored, showing significant increases consistent with enhanced fusion activity. Post-experiment analysis of the palladium electrodes using XRD and SEM revealed substantial lattice deformations, indicative of high deuterium loading and fusion activity. The high-pressure conditions proved to be a crucial factor in optimizing cold fusion reactions.']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import numpy as np\n",
    "import chromadb\n",
    "\n",
    "\n",
    "def init_chroma_db(store_name:str=\"documents\"):\n",
    "    \"\"\" Initialize ChromaDB client. \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./cromadb\")\n",
    "    vector_store = chroma_client.get_or_create_collection(store_name)\n",
    "    return chroma_client, vector_store\n",
    "\n",
    "def chunk_embed_text(text):\n",
    "    \"\"\"Generate embeddings for the text using a transformer model..\"\"\"\n",
    "\n",
    "    chunks = []\n",
    "    ids = []\n",
    "    ct = 0\n",
    "    for chunk in text:\n",
    "        chunks.append(chunk)\n",
    "        ids.append(f\"id_{str(ct)}\")\n",
    "        ct += 1\n",
    "\n",
    "    return chunks, ids\n",
    "\n",
    "\n",
    "def preprocess_text_to_chroma(text, vector_store): \n",
    "    \"\"\"Process text and store chunks in ChromaDB.\"\"\"\n",
    "    \n",
    "    chunks, ids = chunk_embed_text(text)\n",
    "    vector_store.add(documents=chunks, ids=ids)\n",
    "    \n",
    "# Example text corpus\n",
    "text = parse_experiments()\n",
    "\n",
    "chroma_client, vector_store = init_chroma_db(\"documents\")\n",
    "preprocess_text_to_chroma(text, \n",
    "                          vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What were the key findings in the last successful cold fusion experiment?\"\n",
    "# question = \"What is the color of palladium?\"\n",
    "results = vector_store.query(query_texts=question, n_results=5)\n",
    "\n",
    "documents = \"\\n\".join(results['documents'][0])\n",
    "\n",
    "prompt = f\"\"\"DOCUMENT:\n",
    "{documents}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Answer the users QUESTION using the DOCUMENT text above.\n",
    "Keep your answer ground in the facts of the DOCUMENT.\n",
    "If the DOCUMENT doesn’t contain the facts to answer the QUESTION return 'NONE'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "host = \"\"\n",
    "model = \"llama3\"\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": prompt}\n",
    "messages = [system_message]\n",
    "\n",
    "response = Client(host=host).chat(model=model, messages=messages, options= {\"seed\": 42, \"top_p\": 0.9, \"temperature\": 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3',\n",
       " 'created_at': '2024-06-13T16:04:55.040275131Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'The key finding in the last successful cold fusion experiment (Experiment20) was that the combination of palladium and silver electrodes, with a lithium chloride electrolyte, proved to be highly effective in enhancing cold fusion reactions. The experiment showed significant heat generation, with energy output surpassing input by 25% after 8 hours.'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 20054003340,\n",
       " 'load_duration': 1495696,\n",
       " 'prompt_eval_count': 1125,\n",
       " 'prompt_eval_duration': 7309602000,\n",
       " 'eval_count': 66,\n",
       " 'eval_duration': 12585410000}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "chunk_size = 500  # Define your chunk size\n",
    "overlap_size = 50  # Define your overlap size\n",
    "\n",
    "# Example text corpus\n",
    "text = get_coldf_experiment_text()\n",
    "# text = \"\"\"\n",
    "# CHAPTER I\n",
    "# A SHIFTING REEF\n",
    "# The year 1866 was signalised by a remarkable incident, a mysterious and puzzling phenomenon, which doubtless no one has yet forgotten. Not to mention rumours which agitated the maritime population and excited the public mind, even in the interior of continents, seafaring men were particularly excited. Merchants, common sailors, captains of vessels, skippers, both of Europe and America, naval officers of all countries, and the Governments of several states on the two continents, were deeply interested in the matter.\n",
    "\n",
    "# For some time past, vessels had been met by “an enormous thing,” a long object, spindle-shaped, occasionally phosphorescent, and infinitely larger and more rapid in its movements than a whale.\n",
    "\n",
    "# The facts relating to this apparition (entered in various log-books) agreed in most respects as to the shape of the object or creature in question, the untiring rapidity of its movements, its surprising power of locomotion, and the peculiar life with which it seemed endowed. If it was a cetacean, it surpassed in size all those hitherto classified in science. Taking into consideration the mean of observations made at divers times,—rejecting the timid estimate of those who assigned to this object a length of two hundred feet, equally with the exaggerated opinions which set it down as a mile in width and three in length,—we might fairly conclude that this mysterious being surpassed greatly all dimensions admitted by the ichthyologists of the day, if it existed at all. And that it did exist was an undeniable fact; and, with that tendency which disposes the human mind in favour of the marvellous, we can understand the excitement produced in the entire world by this supernatural apparition. As to classing it in the list of fables, the idea was out of the question.\n",
    "\n",
    "# On the 20th of July, 1866, the steamer Governor Higginson, of the Calcutta and Burnach Steam Navigation Company, had met this moving mass five miles off the east coast of Australia. Captain Baker thought at first that he was in the presence of an unknown sandbank; he even prepared to determine its exact position, when two columns of water, projected by the inexplicable object, shot with a hissing noise a hundred and fifty feet up into the air. Now, unless the sandbank had been submitted to the intermittent eruption of a geyser, the Governor Higginson had to do neither more nor less than with an aquatic mammal, unknown till then, which threw up from its blow-holes columns of water mixed with air and vapour.\n",
    "\n",
    "# Similar facts were observed on the 23rd of July in the same year, in the Pacific Ocean, by the Columbus, of the West India and Pacific Steam Navigation Company. But this extraordinary cetaceous creature could transport itself from one place to another with surprising velocity; as, in an interval of three days, the Governor Higginson and the Columbus had observed it at two different points of the chart, separated by a distance of more than seven hundred nautical leagues.\n",
    "\n",
    "# Fifteen days later, two thousand miles farther off, the Helvetia, of the Compagnie-Nationale, and the Shannon, of the Royal Mail Steamship Company, sailing to windward in that portion of the Atlantic lying between the United States and Europe, respectively signalled the monster to each other in 42° 15′ N. lat. and 60° 35′ W. long. In these simultaneous observations they thought themselves justified in estimating the minimum length of the mammal at more than three hundred and fifty feet, as the Shannon and Helvetia were of smaller dimensions than it, though they measured three hundred feet over all.\n",
    "\n",
    "# Now the largest whales, those which frequent those parts of the sea round the Aleutian, Kulammak, and Umgullich islands, have never exceeded the length of sixty yards, if they attain that.\n",
    "\n",
    "# These reports arriving one after the other, with fresh observations made on board the transatlantic ship Pereire, a collision which occurred between the Etna of the Inman line and the monster, a procès verbal directed by the officers of the French frigate Normandie, a very accurate survey made by the staff of Commodore Fitz-James on board the Lord Clyde, greatly influenced public opinion. Light-thinking people jested upon the phenomenon, but grave practical countries, such as England, America, and Germany, treated the matter more seriously.\n",
    "\n",
    "# In every place of great resort the monster was the fashion. They sang of it in the cafés, ridiculed it in the papers, and represented it on the stage. All kinds of stories were circulated regarding it. There appeared in the papers caricatures of every gigantic and imaginary creature, from the white whale, the terrible “Moby Dick” of hyperborean regions, to the immense kraken whose tentacles could entangle a ship of five hundred tons, and hurry it into the abyss of the ocean. The legends of ancient times were even resuscitated, and the opinions of Aristotle and Pliny revived, who admitted the existence of these monsters, as well as the Norwegian tales of Bishop Pontoppidan, the accounts of Paul Heggede, and, last of all, the reports of Mr. Harrington (whose good faith no one could suspect), who affirmed that, being on board the Castillan, in 1857, he had seen this enormous serpent, which had never until that time frequented any other seas but those of the ancient “Constitutionnel.”\n",
    "\n",
    "# Then burst forth the interminable controversy between the credulous and the incredulous in the societies of savants and the scientific journals. “The question of the monster” inflamed all minds. Editors of scientific journals, quarrelling with believers in the supernatural, spilled seas of ink during this memorable campaign, some even drawing blood; for, from the sea-serpent they came to direct personalities.\n",
    "\n",
    "# For six months war was waged with various fortune in the leading articles of the Geographical Institution of Brazil, the Royal Academy of Science of Berlin, the British Association, the Smithsonian Institution of Washington, in the discussions of the “Indian Archipelago,” of the Cosmos of the Abbé Moigno, in the Mittheilungen of Petermann, in the scientific chronicles of the great journals of France and other countries. The cheaper journals replied keenly and with inexhaustible zest. These satirical writers parodied a remark of Linnæus, quoted by the adversaries of the monster, maintaining “that nature did not make fools,” and adjured their contemporaries not to give the lie to nature, by admitting the existence of krakens, sea-serpents, “Moby Dicks,” and other lucubrations of delirious sailors. At length an article in a well-known satirical journal by a favourite contributor, the chief of the staff, settled the monster, like Hippolytus, giving it the death-blow amidst an universal burst of laughter. Wit had conquered science.\n",
    "\n",
    "# During the first months of the year 1867 the question seemed buried, never to revive, when new facts were brought before the public. It was then no longer a scientific problem to be solved, but a real danger seriously to be avoided. The question took quite another shape. The monster became a small island, a rock, a reef, but a reef of indefinite and shifting proportions.\n",
    "\n",
    "# On the 5th of March, 1867, the Moravian, of the Montreal Ocean Company, finding herself during the night in 27° 30′ lat. and 72° 15′ long., struck on her starboard quarter a rock, marked in no chart for that part of the sea. Under the combined efforts of the wind and its four hundred horse-power, it was going at the rate of thirteen knots. Had it not been for the superior strength of the hull of the Moravian, she would have been broken by the shock and gone down with the 237 passengers she was bringing home from Canada.\n",
    "\n",
    "# The accident happened about five o’clock in the morning, as the day was breaking. The officers of the quarter-deck hurried to the after-part of the vessel. They examined the sea with the most scrupulous attention. They saw nothing but a strong eddy about three cables’ length distant, as if the surface had been violently agitated. The bearings of the place were taken exactly, and the Moravian continued its route without apparent damage. Had it struck on a submerged rock, or on an enormous wreck? they could not tell; but on examination of the ship’s bottom when undergoing repairs, it was found that part of her keel was broken.\n",
    "\n",
    "# This fact, so grave in itself, might perhaps have been forgotten like many others if, three weeks after, it had not been re-enacted under similar circumstances. But, thanks to the nationality of the victim of the shock, thanks to the reputation of the company to which the vessel belonged, the circumstance became extensively circulated.\n",
    "\n",
    "# The 13th of April, 1867, the sea being beautiful, the breeze favourable, the Scotia, of the Cunard Company’s line, found herself in 15° 12′ long. and 45° 37′ lat. She was going at the speed of thirteen knots and a half.\n",
    "\n",
    "# At seventeen minutes past four in the afternoon, whilst the passengers were assembled at lunch in the great saloon, a slight shock was felt on the hull of the Scotia, on her quarter, a little aft of the port-paddle.\n",
    "\n",
    "# The Scotia had not struck, but she had been struck, and seemingly by something rather sharp and penetrating than blunt. The shock had been so slight that no one had been alarmed, had it not been for the shouts of the carpenter’s watch, who rushed on to the bridge, exclaiming, “We are sinking! we are sinking!” At first the passengers were much frightened, but Captain Anderson hastened to reassure them. The danger could not be imminent. The Scotia, divided into seven compartments by strong partitions, could brave with impunity any leak. Captain Anderson went down immediately into the hold. He found that the sea was pouring into the fifth compartment; and the rapidity of the influx proved that the force of the water was considerable. Fortunately this compartment did not hold the boilers, or the fires would have been immediately extinguished. Captain Anderson ordered the engines to be stopped at once, and one of the men went down to ascertain the extent of the injury. Some minutes afterwards they discovered the existence of a large hole, of two yards in diameter, in the ship’s bottom. Such a leak could not be stopped; and the Scotia, her paddles half submerged, was obliged to continue her course. She was then three hundred miles from Cape Clear, and after three days’ delay, which caused great uneasiness in Liverpool, she entered the basin of the company.\n",
    "\n",
    "# The engineers visited the Scotia, which was put in dry dock. They could scarcely believe it possible; at two yards and a half below water-mark was a regular rent, in the form of an isosceles triangle. The broken place in the iron plates was so perfectly defined that it could not have been more neatly done by a punch. It was clear, then, that the instrument producing the perforation was not of a common stamp; and after having been driven with prodigious strength, and piercing an iron plate 1-3/8 inches thick, had withdrawn itself by a retrograde motion truly inexplicable.\n",
    "\n",
    "# Such was the last fact, which resulted in exciting once more the torrent of public opinion. From this moment all unlucky casualties which could not be otherwise accounted for were put down to the monster. Upon this imaginary creature rested the responsibility of all these shipwrecks, which unfortunately were considerable; for of three thousand ships whose loss was annually recorded at Lloyd’s, the number of sailing and steam ships supposed to be totally lost, from the absence of all news, amounted to not less than two hundred!\n",
    "\n",
    "# Now, it was the “monster” who, justly or unjustly, was accused of their disappearance, and, thanks to it, communication between the different continents became more and more dangerous. The public demanded peremptorily that the seas should at any price be relieved from this formidable cetacean. \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "context_encoder, context_tokenizer = get_context_encoder_tokenizer()\n",
    "chroma_client, vector_store = init_chroma_db(\"documents\")\n",
    "preprocess_text_to_chroma(text, vector_store, chunk_size, overlap_size, context_tokenizer=context_tokenizer, context_encoder=context_encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Who is Alexandre Dumas?\"\n",
    "# _, query_embeddings, _   = chunk_embed_text(query_text, chunk_size, overlap_size,context_encoder, context_tokenizer)\n",
    "\n",
    "# results = vector_store.query(query_embeddings, n_results=3)\n",
    "results = vector_store.query(query_texts=query_text, n_results=3)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE 1\n",
    "\n",
    "\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "text = \"apple\"\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "inputs = context_tokenizer(text, return_tensors='pt')\n",
    "embeddings = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "print(f\"Embeddings:{embeddings}\")\n",
    "print(f\"Lenght embeddings:{len(embeddings)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "model = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "embeddings = model(input_ids).pooler_output\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:{'input_ids': tensor([[ 101, 1996, 4589, 2015, 1005, 3392,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Embeddings:[-0.42088955640792847, -0.16487939655780792, -0.07183636724948883, -0.257621705532074, -0.0057326615788042545, 0.6571173071861267, 0.22251904010772705, 0.7907621264457703, -0.4416864812374115, 0.03407983109354973, -0.12442491948604584, -0.010331674478948116, -0.19684024155139923, 0.14910925924777985, 0.1317194104194641, -0.028618350625038147, 0.44797956943511963, 1.1473305225372314, -0.14583437144756317, -0.3969254791736603, -0.16986659169197083, -0.21098089218139648, 0.18620631098747253, 0.04666803404688835, 0.9896305203437805, -0.3227349817752838, 0.256872296333313, 0.0930483490228653, 0.4392845928668976, -0.03565487265586853, -0.4870366156101227, 0.02131262980401516, 0.12234935909509659, -0.9369249939918518, -0.013389546424150467, -1.0342408418655396, -0.42550724744796753, -0.6470987796783447, -0.02905494160950184, -0.25023573637008667, -0.35644373297691345, -0.25517362356185913, 0.4104057848453522, 0.5533112287521362, -0.031112952157855034, -0.47778254747390747, -2.101590871810913, 0.10475896298885345, 0.12071957439184189, 0.5271731019020081, 0.38076314330101013, 0.2795260548591614, 0.29388636350631714, 0.13643066585063934, 0.5146356225013733, 0.5319643616676331, -0.5138277411460876, 0.4871353805065155, 0.7345484495162964, -0.3633114695549011, -0.09112191200256348, 0.2250242829322815, 0.08905872702598572, 0.5103476047515869, -0.28193211555480957, 0.24993324279785156, 0.4405142366886139, 0.4396277368068695, -0.190933495759964, 0.1510673612356186, 0.2802603840827942, -0.6202397346496582, -0.36396554112434387, -0.38416507840156555, -0.5708698034286499, -0.7651342153549194, -0.2514882981777191, -0.0195356085896492, 0.36257368326187134, 0.18246899545192719, 0.03644733875989914, 0.171301007270813, 0.5032666325569153, 0.1554839313030243, -0.1340898722410202, 0.3999428153038025, -0.43369239568710327, -0.4023618698120117, -0.561855137348175, 0.06416292488574982, -0.6739999651908875, 0.15553544461727142, 0.4805756211280823, 0.05163206160068512, 0.19556047022342682, 0.0038235504180192947, -0.07746075093746185, 0.28024667501449585, 0.21067672967910767, 0.4477708637714386, -0.3414314389228821, 0.7584895491600037, -0.03490127995610237, -0.11252719908952713, -0.9217464923858643, 0.28684917092323303, 0.12662993371486664, 0.05082952231168747, -0.06262587755918503, -0.5325684547424316, -0.48993563652038574, 0.1308455765247345, -0.1260938197374344, 0.3950199484825134, -0.8954779505729675, 0.616962194442749, 0.5669580101966858, -0.2569005787372589, -0.581280529499054, -0.5473470687866211, 0.21027430891990662, 0.43583086133003235, 0.41487425565719604, 0.1990961879491806, 0.17050941288471222, -0.2084953635931015, -0.14071936905384064, 0.12672901153564453, -0.31226208806037903, 0.44089168310165405, 0.08054251223802567, 0.4388267993927002, -0.19742654263973236, -0.42083433270454407, 0.1424727588891983, -0.3723982870578766, -0.015870926901698112, 0.48901844024658203, 0.5598441958427429, 0.3339134454727173, -0.8733572363853455, 0.08476254343986511, -0.8667862415313721, 0.10411521047353745, -0.3585263788700104, 0.13926571607589722, -0.41227078437805176, -0.34261876344680786, 0.2503800094127655, -0.2101762294769287, 0.5689419507980347, 0.16034092009067535, -0.4063316881656647, -0.05376172438263893, -0.0460674986243248, 0.6215174794197083, 0.20023006200790405, -0.4244174659252167, -0.016317062079906464, -0.08785898238420486, -0.48247551918029785, -0.4251522719860077, 0.23044632375240326, -0.36571431159973145, -0.05620606243610382, -0.1299850046634674, 0.1595834642648697, -0.11660757660865784, 0.27172115445137024, 0.4103012979030609, -0.40740787982940674, 0.11929938942193985, 0.2019718885421753, -0.6761572360992432, -0.001982933608815074, -0.11331472545862198, 0.2514955997467041, -0.21274155378341675, -0.34025949239730835, 0.07024305313825607, -0.3043883442878723, 0.23349320888519287, -0.27545782923698425, -0.3212355673313141, -0.17783696949481964, -0.2964111566543579, -0.03830360993742943, 0.20508813858032227, 0.5052873492240906, 0.008909684605896473, 0.09143611788749695, -0.36019110679626465, 0.2936052083969116, 0.03270748257637024, 0.10265100747346878, -0.06648028641939163, -0.7096356153488159, 0.09777825325727463, 0.08621587604284286, -0.3317985534667969, 0.1613783985376358, 0.14995121955871582, 0.2610096037387848, -0.1720210760831833, -0.9772909283638, 0.5934301614761353, -0.08058087527751923, -0.3904678523540497, 0.7746549248695374, 0.30884140729904175, 0.08284197747707367, -0.4640630781650543, 0.05744939297437668, -0.8891255855560303, 0.3262282907962799, 0.15899501740932465, -0.07538862526416779, -0.2945723235607147, -0.2584126591682434, -0.10843999683856964, 0.21312424540519714, 0.0051468838937580585, 0.2151680439710617, 0.4532838463783264, -0.6500982046127319, 0.5071181058883667, 0.26629212498664856, 0.007894630543887615, 0.4937839210033417, -0.43322935700416565, 0.21292263269424438, -0.4974961578845978, -0.14114883542060852, 0.012129291892051697, -0.1965891569852829, 0.17928555607795715, -0.11603008210659027, -0.4059930443763733, 0.5700361132621765, 0.31336379051208496, -0.14868010580539703, -0.13162080943584442, -0.34007513523101807, 0.3513232171535492, 0.1647074669599533, -0.45483288168907166, -0.22819386422634125, 0.0955318734049797, -0.16847899556159973, -0.018499599769711494, -0.17028824985027313, -0.3674727976322174, -0.07121986895799637, 0.3454788327217102, 0.4715116322040558, -0.3737838566303253, -0.2258845567703247, -0.04696376249194145, 0.09786567836999893, 0.11490309238433838, -0.20423132181167603, 0.17224055528640747, -0.07681457698345184, 0.4736325144767761, -0.05393882095813751, 0.2922845482826233, -0.1400326043367386, -0.5838339924812317, 0.4327724575996399, -0.0374942310154438, 0.13529539108276367, -0.08227312564849854, -0.5356168746948242, -1.040365219116211, -0.30524909496307373, -0.6200441122055054, 0.09144986420869827, 0.049340393394231796, 0.30982351303100586, -0.31949636340141296, 0.13965144753456116, 0.22439061105251312, 0.02476506307721138, -0.16350506246089935, 0.36120519042015076, -0.20617423951625824, 0.36831748485565186, -0.2034187912940979, 0.06882183998823166, -0.11237452179193497, 0.2915479838848114, 0.000580501276999712, 0.031055377796292305, 0.35178419947624207, 0.11846107244491577, 0.04187528043985367, 0.1061590388417244, 0.3594311773777008, 0.11120323091745377, -1.0065593719482422, 0.27063024044036865, 0.23697569966316223, -0.10873277485370636, -0.2033708542585373, 0.3125104606151581, 0.5944200754165649, -0.11608724296092987, 0.47348156571388245, -5.755098819732666, -0.22408224642276764, 0.00903002917766571, 0.24182310700416565, 0.04729709401726723, -0.14516733586788177, 0.36319947242736816, -0.3733524978160858, 0.024940727278590202, -0.4790205955505371, 0.18476641178131104, 0.42458224296569824, 0.5153281092643738, 0.009494809433817863, 0.004339034203439951, 0.05745115876197815, -0.4860181510448456, -0.6574652194976807, 0.17964018881320953, -0.5092754364013672, -0.23597313463687897, -0.24758903682231903, -0.04469411075115204, -0.1832902580499649, -0.33674299716949463, 0.7602760791778564, 0.12189317494630814, -0.3114267885684967, -0.7952359318733215, 0.21634577214717865, -0.6180269122123718, -0.34542304277420044, 0.2763558626174927, -0.09883905202150345, -0.5949169993400574, -0.08593430370092392, -0.16814468801021576, -0.4095025062561035, 0.25110113620758057, 0.5931419730186462, -0.24313639104366302, -0.1448359340429306, 0.9552470445632935, 0.8286609649658203, -0.0020362194627523422, -0.14610353112220764, -0.5024058222770691, -0.6652001142501831, -0.24818019568920135, 0.8623352646827698, 0.24069319665431976, 0.24558429419994354, 0.6006998419761658, -0.3228157162666321, 0.3846554458141327, 0.11519726365804672, 0.32197433710098267, -0.08086785674095154, 0.29763263463974, -0.21229040622711182, 0.2104080766439438, 0.24835240840911865, 0.4755692183971405, -0.08478157967329025, 0.48359087109565735, 0.004916276317089796, 0.08490532636642456, 0.06997709721326828, 0.3798748850822449, -0.2796279191970825, -0.0482599176466465, -0.8218556046485901, -0.31687310338020325, -0.8496206402778625, -0.3616403043270111, -0.1959414780139923, -1.1007401943206787, -0.0736154094338417, -0.23626133799552917, -0.257805734872818, -0.2890426516532898, -0.18173997104167938, -0.21489325165748596, 0.003204889129847288, -0.07318242639303207, -0.6108125448226929, 0.011063635349273682, -0.09237051755189896, -0.45785844326019287, -0.13101239502429962, -0.13732220232486725, -0.04887036234140396, -0.23541505634784698, 0.2545757591724396, 0.6243364214897156, 0.6099300384521484, -0.36898428201675415, 0.32177630066871643, 0.5189769864082336, 0.19302970170974731, 0.6336076855659485, -0.03817847743630409, -0.5348409414291382, -0.2614418566226959, -0.15782663226127625, -0.34045442938804626, -0.42754659056663513, 0.2001437395811081, 0.29171761870384216, -0.5726830363273621, 0.6310264468193054, -0.23950214684009552, -0.12762312591075897, -0.15574562549591064, 0.7115177512168884, 0.05855850130319595, 0.20595228672027588, 0.021415216848254204, 0.45535674691200256, -0.19714586436748505, 0.0029479118529707193, 0.5645169615745544, 0.2201840728521347, -0.16310624778270721, -0.16776394844055176, -0.1312139332294464, -0.2979017198085785, -0.7157998085021973, -0.09094791114330292, -0.17569661140441895, -0.2603284418582916, 0.030648017302155495, 0.618883490562439, 0.39393752813339233, -0.3080756962299347, -0.4199959635734558, -0.5260603427886963, -0.7709641456604004, 0.16858404874801636, -0.19937346875667572, -0.6085604429244995, 0.3111250698566437, 0.5258525609970093, 0.25867533683776855, 0.7127819061279297, 0.34815624356269836, -0.2348334938287735, -0.3348160982131958, -0.4047265946865082, 0.33781325817108154, -0.14824417233467102, 0.042055077850818634, 0.7112579941749573, 0.01143400464206934, -0.5322903990745544, -0.3117580711841583, -0.03482285141944885, -0.22638896107673645, -0.5367016196250916, 0.005776287522166967, 0.8506456017494202, -0.4222327768802643, -0.8301683068275452, -0.10663007199764252, 0.37767165899276733, -0.15933507680892944, 0.2416570633649826, -0.666628360748291, -0.12361343204975128, 1.0182981491088867, -0.015267680399119854, 0.41369298100471497, -0.18818674981594086, 0.26708006858825684, -0.1003418043255806, 0.19473746418952942, -0.3372480273246765, -0.09024405479431152, 0.26414185762405396, -0.9252747297286987, 0.0808681920170784, 0.21159112453460693, -0.5400103330612183, 0.6228399872779846, 0.25021329522132874, -0.6043751239776611, -0.3514316976070404, -0.6805133819580078, -0.3290254771709442, 0.4353381395339966, -0.06347187608480453, 0.10487546026706696, 0.42534688115119934, 0.07841300219297409, -0.4142710566520691, 0.1235828548669815, -0.07051154971122742, -0.0779888778924942, -0.2700294256210327, -0.14590120315551758, 0.07834279537200928, -0.46537619829177856, -1.1392868757247925, 0.17404919862747192, -0.1438433676958084, -0.2685050964355469, 1.136144995689392, 0.47276875376701355, -0.7572668194770813, 0.3749523460865021, 0.02398209273815155, -0.6438416242599487, 0.384721577167511, 0.3332383632659912, -0.10448943823575974, 0.11845720559358597, -0.15183493494987488, 0.08397320657968521, -0.5608497262001038, -0.40179020166397095, 0.5870368480682373, -0.334337443113327, 0.01492722425609827, -0.4768349826335907, 0.26318269968032837, 0.6175687313079834, 0.6533146500587463, 0.41502872109413147, 0.48540934920310974, 0.2961561679840088, 0.18333685398101807, -0.23233725130558014, 0.5542311668395996, 0.3955543041229248, -0.048084843903779984, 0.16182202100753784, -0.557121753692627, 0.012917790561914444, -0.026893598958849907, 0.543300211429596, 0.2532844841480255, 0.5184590816497803, -0.7196633219718933, -0.2098473459482193, -0.46637988090515137, 0.370654433965683, 0.21014592051506042, -0.2882276773452759, -0.5424975752830505, -0.04485755413770676, 0.1023455262184143, -0.17508624494075775, 0.06725161522626877, 0.30281558632850647, 0.54618901014328, -0.32367977499961853, -0.19521214067935944, 0.41783392429351807, 0.10428125411272049, -0.22162950038909912, 0.13597935438156128, -0.04541667550802231, 0.073968306183815, 0.6465617418289185, 0.17119859158992767, -0.4830150902271271, -0.2933872938156128, -0.5972276926040649, 0.24879933893680573, -0.22836002707481384, -0.45439383387565613, -0.011842964217066765, 0.47891008853912354, 0.6725025177001953, -0.3615584075450897, 0.38732823729515076, -0.4670356512069702, -0.1851930320262909, -0.022298499941825867, -0.11486745625734329, 0.017226332798600197, 0.5541085004806519, -0.5638140439987183, -0.25233861804008484, -0.359518438577652, -0.08612941205501556, -0.25205138325691223, 0.23322241008281708, 0.3457762897014618, 0.17575131356716156, -0.10938301682472229, 0.14222347736358643, 0.5366150140762329, 0.07217930257320404, 0.5165820717811584, 0.48797541856765747, 0.13311290740966797, -0.02411418780684471, 0.22049233317375183, -0.27553582191467285, -0.8795710802078247, 1.2538840770721436, 0.6896026730537415, 0.18697696924209595, -0.3899109363555908, 0.46311917901039124, -0.2250298410654068, -0.20757131278514862, -0.5037038922309875, -0.5862064957618713, 0.3451090455055237, 0.4510851800441742, -0.26613178849220276, 0.12302645295858383, -0.19581767916679382, 0.45202651619911194, 0.47194522619247437, -0.2960028648376465, -0.06563986837863922, 0.6530278921127319, 0.04009845107793808, 0.35072436928749084, 0.3341098725795746, 0.07170234620571136, 0.4970589876174927, 0.7757614850997925, -0.2690342962741852, 0.1258084774017334, 0.3240978717803955, 0.18685491383075714, 0.42037633061408997, -0.2272465080022812, -0.2816125452518463, 0.7823498249053955, 0.42515823245048523, -0.4031783640384674, 0.5686182379722595, -0.7479373812675476, 0.13833756744861603, 0.2500629425048828, 1.0695542097091675, -0.14274799823760986, -0.23818807303905487, 0.06297634541988373, 0.38333970308303833, 0.06280269473791122, 0.16306884586811066, 0.27935823798179626, -0.04746215417981148, -0.1019284725189209, 0.3178311586380005, -0.27756184339523315, 0.3851682245731354, -0.731857180595398, 0.5427412986755371, 0.3728781044483185, -0.025433696806430817, 0.21456417441368103, -0.4650742709636688, -0.8344529867172241, 0.19549433887004852, 0.6728854775428772, 0.295554518699646, 0.36209622025489807, -0.90985506772995, 0.7027263641357422, 0.08674924820661545, 0.3547123372554779, -0.24547085165977478, -0.0711665078997612, 0.24848943948745728, 0.017864197492599487, -0.2571035325527191, 0.04918597266077995, 0.21834388375282288, 0.16642582416534424, -0.20740360021591187, 0.2663494050502777, 0.6298649907112122, 0.9861870408058167, 0.10600703209638596, -0.12679000198841095, -0.07156594097614288, 0.08073250949382782, 0.4431289732456207, -0.16416136920452118, 0.05909207835793495, -0.4378349483013153, -0.9008724689483643, 0.05906018242239952, 0.012752007693052292, 0.09474669396877289, -0.0028293898794800043, -0.1373201310634613, -0.11133798211812973, 0.3937424421310425, -0.5317690968513489, 0.823246419429779, -0.5562568306922913, -0.11068806797266006, 0.07339999079704285, 0.22780320048332214, 0.01251349225640297, 0.46712973713874817, -0.16867868602275848, 0.49150121212005615, -0.39119836688041687, -0.4929761290550232, -0.16346918046474457, 0.4115060865879059, 0.777546763420105, 0.36106327176094055, 0.2331143021583557, 0.2206512987613678, -0.4453422725200653, 0.4543158710002899, 0.4336200952529907, 0.17336976528167725, -0.08400882035493851, -0.29677584767341614, 0.3725200295448303, -0.8616463541984558, 0.1117357462644577, 0.8301098942756653, -0.3682037591934204, 0.1637352705001831, 0.18730664253234863, 0.5901370644569397, -0.3077077269554138, 0.045507557690143585, 0.30384159088134766, -0.07853025943040848, -0.18998605012893677, 0.4712003767490387, -0.6688927412033081, -0.11208866536617279, 0.6659655570983887, 0.620883047580719, -0.1420542299747467, 0.12254632264375687, -0.4699974060058594, -0.2790156900882721, 0.673613429069519, -0.700143575668335, -0.962279200553894, -0.31654423475265503, -0.15420116484165192, -0.31033554673194885, -0.37222787737846375, -0.3560487926006317, 0.09209568798542023, -0.8725925087928772, 0.3511198163032532, -0.097291961312294, 0.07951144129037857, -0.036338429898023605, 0.018428746610879898, -0.236576646566391, -0.029671525582671165, 0.18298251926898956]\n",
      "Lenght embeddings:768\n"
     ]
    }
   ],
   "source": [
    "# CODE 1\n",
    "\n",
    "\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "\n",
    "text = \"the oranges' tree\"\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "inputs = context_tokenizer(text, return_tensors='pt')\n",
    "embeddings = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "print(f\"Inputs:{inputs}\")\n",
    "\n",
    "print(f\"Embeddings:{embeddings}\")\n",
    "print(f\"Lenght embeddings:{len(embeddings)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.79940783]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "a1 = \"Dr. Emily D. Jensen\"\n",
    "a2 = \"\"\"Dr. Emily D. Jensen, led the first experiment.\"\"\"\n",
    "\n",
    "\n",
    "inputs = context_tokenizer(a1, return_tensors='pt')\n",
    "embeddings1 = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "\n",
    "inputs = context_tokenizer(a2, return_tensors='pt')\n",
    "embeddings2 = context_encoder(**inputs).pooler_output.detach().numpy()[0].tolist()\n",
    "\n",
    "cosine_similarity([embeddings1], [embeddings2])\n",
    "\n",
    "# [0.83924436"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
