{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgrodrigues/.pyenv/versions/3.11.9/envs/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from rag_1 import parse_experiments, init_chroma_db, preprocess_text_to_chroma, get_inference, chunk_embed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Get the secret experiment text\n",
    "text = parse_experiments()\n",
    "\n",
    "# Get the Vector Database Client\n",
    "chroma_client, vector_store = init_chroma_db(\"documents-1\")\n",
    "\n",
    "# Put the secret experiments in the vector database\n",
    "preprocess_text_to_chroma(text=text, vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================\n",
      "\n",
      "Prompt: DOCUMENT:\n",
      "# Experiment 1\n",
      "\n",
      "To ensure accuracy, additional measurements included the analysis of gas output.\n",
      "\n",
      "\n",
      "# Experiment 20\n",
      "\n",
      "Additional investigations included monitoring the electrodes' structural integrity using SEM and XRD.\n",
      "\n",
      "\n",
      "# Experiment 1\n",
      "\n",
      "This increase suggested that deuterium nuclei might be fusing within the palladium lattice.\n",
      "\n",
      "\n",
      "\n",
      "QUESTION:\n",
      "What material was used for the electrodes in Experiment 1?\n",
      "\n",
      "INSTRUCTIONS:\n",
      "Answer the users QUESTION using the DOCUMENT markdown text above.\n",
      "Give short and concise answers.\n",
      "Keep your answer ground in the facts of the DOCUMENT.\n",
      "If the DOCUMENT doesnâ€™t contain the facts to answer the QUESTION return 'NONE'\n",
      "\n",
      "================================\n",
      "\n",
      "Database Results: {'ids': [['# Experiment 1_5', '# Experiment 20_5', '# Experiment 1_7']], 'distances': [[65.06888580322266, 67.44291499264398, 68.28384399414062]], 'metadatas': [[None, None, None]], 'embeddings': None, 'documents': [['# Experiment 1\\n\\nTo ensure accuracy, additional measurements included the analysis of gas output.\\n\\n', \"# Experiment 20\\n\\nAdditional investigations included monitoring the electrodes' structural integrity using SEM and XRD.\\n\\n\", '# Experiment 1\\n\\nThis increase suggested that deuterium nuclei might be fusing within the palladium lattice.\\n\\n']], 'uris': None, 'data': None}\n",
      "\n",
      "================================\n",
      "\n",
      "Response: The material used for the electrodes in Experiment 1 is not specified in the provided DOCUMENT. Therefore, my answer is:\n",
      "\n",
      "NONE\n",
      "\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the query from the end user, search in the vector database.\n",
    "question = input(\"Please enter question: \")\n",
    "\n",
    "# Get the encoder and tokenizer \n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "# Prepara the data and get the answer\n",
    "response, prompt, db_results = get_inference(question, context_encoder, context_tokenizer, vector_store)\n",
    "\n",
    "print(\"\\n================================\\n\")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"\\n================================\\n\")\n",
    "print(f\"Database Results: {db_results}\")\n",
    "print(\"\\n================================\\n\")\n",
    "print(f\"Response: {response['message']['content']}\")\n",
    "print(\"\\n================================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
